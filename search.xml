<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>EA-HAS-Bench</title>
    <url>/2023/11/16/EA-HAS-Bench/</url>
    <content><![CDATA[<h1 id="研究背景">1 研究背景</h1>
<p>随着深度学习技术的发展，训练数据和模型规模快速增长，导致训练模型的能耗也大幅增加，并对碳中和产生负面影响。</p>
<p>对于AutoML算法，例如<strong>神经架构搜索（Neural Architecture Search,
NAS）</strong>和<strong>超参数优化（Hyperparameter Optimization,
HPO）</strong>，避免了神经架构和超参数调整的人工处理，但需要重复训练大量计算密集型深度模型，从而导致显着的能源消耗和碳排放。</p>
<span id="more"></span>
<p>与此同时，现有的 NAS
研究主要集中于搜索神经网络模型的资源成本上，如参数大小、浮点运算（FLOPS）或延迟，而直接分析模型性能和能源消耗的研究则很少。</p>
<p>因此，必须开发具备能源感知 (Energy Aware, EA) 的 AutoML
方法，使其能够<strong>权衡模型性能和能量消耗</strong>。</p>
<h1 id="研究成果">2 研究成果</h1>
<ul>
<li>提出首个大规模能耗感知超参数和架构搜索基准——EA-HAS-Bench（energy-aware
hyperparameter and architecture search benchmark
），以在性能和搜索能耗之间实现更好的权衡；</li>
<li>EA-HAS-Bench
提供了一个大规模的架构/超参数联合搜索空间，涵盖了与能耗相关的多样化配置；</li>
<li>开发了一种新的代理模型，专门为大型联合搜索空间设计，该模型提出了一种基于B́ezier曲线的模型来预测具有无限形状和长度的学习曲线。</li>
</ul>
<h1 id="研究内容">3 研究内容</h1>
<h2 id="ea-has-bench-的创建">3.1 EA-HAS-Bench 的创建</h2>
<p>EA-HAS-Bench 的搜索空间由两部分组成：</p>
<ol type="1">
<li>网络架构空间-RegNet（包含<span class="math inline">\(6\times
10^{7}\)</span>个采样点）</li>
<li>用于优化和训练的超参数空间（包含<span
class="math inline">\(540\)</span>个采样点）</li>
</ol>
<img src="/2023/11/16/EA-HAS-Bench/img1.png" class="" title="img1">
<p>由于 EA-HAS-Bench 的搜索空间范围很大，所以即使对于 CIFAR10
这样的小数据集，直接训练空间中的所有配置也不可行。同时，一些如模型性能曲线、搜索能耗成本和运行时间等指标无法直接测量。而对于学习曲线预测，现有
NAS-Bench 提出的代理模型不适用于 EA-HAS-Bench，因为 EA-HAS-Bench
搜索空间中包含不同的最大训练轮次。需要提出一个适用于 EA-HAS-Bench
的全新代理模型。</p>
<p>研究创建了 <strong>B ́ezier Curved-based
Surrogate（BCS）模型</strong>，选择贝塞尔曲线来拟合任意长度的学习曲线。贝塞尔曲线的形状完全由其控制点决定，对任意长度的学习曲线进行回归的任务会被简化为预测贝塞尔曲线控制点。</p>
<p>BCS 模型由以下部分组成：</p>
<ul>
<li>超参数编码器</li>
<li>架构编码器</li>
<li>学习曲线预测网络</li>
</ul>
<img src="/2023/11/16/EA-HAS-Bench/img2.png" class="" title="img2">
<p>当给定一个 RegNet 架构和超参数配置后：</p>
<ol type="1">
<li>将超参数配置表示为独热向量，送入超参数编码器；</li>
<li>将网络配置参数归一化并拼接为向量，送入架构编码器；</li>
<li>将超参数表征和结构表征送入学习曲线预测器，以估计贝塞尔曲线的起始/终止点和控制点。其中学习曲线预测器也由两个分支构成：
<ol type="1">
<li>一个分支预测贝塞尔曲线起点和终点的纵坐标（因为横坐标已知，分别为 0
和 maximum epoch）；</li>
<li>另一分支预测贝塞尔曲线的其他控制点；</li>
</ol></li>
<li>输出通过贝塞尔曲线拟合的学习曲线。</li>
</ol>
<p>在评估代理模型时，使用的评价指标为确定系数 <span
class="math inline">\(R^2\)</span> 和 Kendall 秩相关系数 <span
class="math inline">\(\tau\)</span>，比较的对象为：</p>
<ul>
<li>六个基于参数化学习曲线的模型（exp3, ilog2, pow2, log power, log
linear, vapor pressure）</li>
<li>三个 NAS-Bench-X11 中的代理模型（SVD-XGB, SVD-LGB, SVD-MLP）</li>
</ul>
<img src="/2023/11/16/EA-HAS-Bench/img3.png" class="" title="img3">
<p>经过对比分析，基于参数化学习曲线的模型函数不能很好地拟合 EA-HAS-Bench
中的真实学习曲线，有些高阶函数甚至不能收敛，因为在代理模型中，不同参数的重要性差异很大。</p>
<p>对于 BCS 模型，在 CIFAR10 上，R2 为 0.787，KT 为 0.686，Pearson
相关性为 0.89。在 TinyImageNet 上，R2 为 0.959，KT 为 0.872，Pearson
相关性为 0.97。</p>
<h2 id="ea-nas-bench-的对比">3.2 EA-NAS-Bench 的对比</h2>
<p>与现有的 NAS
基准相比（NAS-Bench-101、NAS-Bench-201、NAS-Bench-301）EA-HAS-Bench
有三个明显的区别：</p>
<ol type="1">
<li>EA-HAS-Bench
在搜索空间的配置类型方面更加多样化，包含了模型架构和训练超参数。
<ul>
<li>与 NAS-Bench-101/201 相比，EA-HAS-Bench
中的配置覆盖了更大的性能范围</li>
<li>与 NAS-Bench-301 相比，虽然 NAS-Bench-301 使用的 DARTS
包含更多的架构，空间中模型的性能没有那么多样化</li>
</ul></li>
<li>EA-HAS-Bench 一个更现实的搜索空间，BSC
的提出能够预测不同最大训练次数的学习曲线。
<ul>
<li>NAS-Bench-X11
是现有的、唯一提供了整个训练过程的完整学习曲线的代用模型方法，但却只适用于具有固定最大训练的学习曲线</li>
</ul></li>
<li>EA-HAS-Bench 提供了一个全周期的能耗，包括训练和推理期间的能耗。
<ul>
<li>大多数现有的基准测试使用模型训练时间作为训练资源预算，不能准确地估计能源成本</li>
<li>能源成本不仅对应于训练时间，还与每单位时间的能量成本有关，而这受到架构和超参数配置的影响</li>
</ul></li>
</ol>
<h2 id="ea-nas-bench-的分析">3.3 EA-NAS-Bench 的分析</h2>
<p><strong>探究不同超参数如何具体影响搜索到的模型性能</strong>。</p>
<ul>
<li>使用经验累积分布empirical cumulative distribution
(ECDF)，来评估搜索空间的质量，从搜索空间中抽取了一组配置并描述其误差分布。</li>
<li>最终得到结论：学习率和优化器的选择可能对搜索空间质量有重要的影响。最大训练次数的大小也与搜索空间的质量呈正相关关系。</li>
</ul>
<p><strong>探究训练时间、训练能源消耗（Training Energy Consumption,
TEC）和精度之间的相关关系</strong>。</p>
<ul>
<li>TEC
和训练时间呈现一定的正相关关系，但相关性不强，尽管训练模型的时间越长，可能产生的能耗成本越高，但最终的成本仍然取决于如功率等许多其他因素。</li>
<li>与此同时，训练一个模型更长的时间（或用更多的能耗）并不能保证更好的准确性，而简单地寻找最佳精度可能也不符合成本效益，因为有相当多的配置具有相同的精度水平。</li>
</ul>
<h2 id="ea-has-bench-的使用">3.4 EA-HAS-Bench 的使用</h2>
<p>首先，评估了一系列算法在搜索能耗成本和模型性能之间的权衡，所评估的算法有：</p>
<ul>
<li>4种单保真算法：随机搜索（RS）、局部搜索（LS）、正则化进化（REA）和
BANANAS</li>
<li>2种多保真算法：Hyperband（HB）和贝叶斯优化Hyperband（BOHB）</li>
</ul>
<img src="/2023/11/16/EA-HAS-Bench/img4.jpg" class="" title="img4">
<p>对于单保真算法，LS是两个数据集中表现最好的算法。这表明，与 NAS-Bench
类似，具有联合搜索空间的 HAS-Bench 也具有局部性，这种属性使搜索空间中
"接近 "的点往往具有相似的性能。</p>
<p>接下来，用另一个与能量相关的目标改造了几种现有的 AutoML
算法，并验证了能量感知 AutoML 在 EA-HAS-Bench上的有效性。</p>
<img src="/2023/11/16/EA-HAS-Bench/img5.png" class="" title="img5">
]]></content>
      <categories>
        <category>Literature Notes</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title>英语词性分类</title>
    <url>/2023/12/05/Part-of-English/</url>
    <content><![CDATA[<h2 id="简述">简述</h2>
<p>英语单词根据其在句子中的作用，可以分为十个大类：</p>
<span id="more"></span>
<table>
<thead>
<tr class="header">
<th>序号</th>
<th>名称</th>
<th>英文</th>
<th>缩写</th>
<th>样例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>名词</td>
<td>noun</td>
<td>n.</td>
<td>boat 船</td>
</tr>
<tr class="even">
<td>2</td>
<td>代词</td>
<td>pronoun</td>
<td>pron.</td>
<td>they 他们</td>
</tr>
<tr class="odd">
<td>3</td>
<td>形容词</td>
<td>adjective</td>
<td>adj.</td>
<td>happy 高兴的</td>
</tr>
<tr class="even">
<td>4</td>
<td>动词</td>
<td>verb</td>
<td>v.</td>
<td>draw 画</td>
</tr>
<tr class="odd">
<td>5</td>
<td>副词</td>
<td>adverb</td>
<td>adv.</td>
<td>fast 快速地</td>
</tr>
<tr class="even">
<td>6</td>
<td>数词</td>
<td>numeral</td>
<td>num.</td>
<td>two 二</td>
</tr>
<tr class="odd">
<td>7</td>
<td>冠词</td>
<td>article</td>
<td>art.</td>
<td>a 一个</td>
</tr>
<tr class="even">
<td>8</td>
<td>介词</td>
<td>preposition</td>
<td>prep.</td>
<td>at 在...</td>
</tr>
<tr class="odd">
<td>9</td>
<td>连词</td>
<td>conjunction</td>
<td>conj.</td>
<td>and 和</td>
</tr>
<tr class="even">
<td>10</td>
<td>感叹词</td>
<td>interjection</td>
<td>interj.</td>
<td>oh 哦</td>
</tr>
</tbody>
</table>
<p>根据它们在句子结构中的作用和成分又被分为实词和虚词。在句子中独立担任成分的是实词；不能在句子中独立担任任何成分的词，叫虚词。（前六种为实词，后四种为虚词）</p>
<h2 id="名词nounn.">1 名词(noun=&gt;n.)</h2>
<h3 id="定义">定义</h3>
<p>人或事物的名称。</p>
<h3 id="分类">分类</h3>
<ul>
<li>专有名词(proper
noun)：专门的，特指的名词，<strong>一般首字母大写</strong>。eg. China,
Earth, Chengdu, June, Tuesday.</li>
<li>普通名词(common
noun)：非专有，可泛指。分为可数名词(cn.)和不可数名词(un.) eg.
可数：flower, guitar, plant; 不可数：water, money,
grass（可数名词有单数和复数的区别）</li>
</ul>
<p>名词在句子中可做<strong>主语、宾语、定语</strong>等。</p>
<h3 id="名词复数的规则变化">名词复数的规则变化</h3>
<table>
<thead>
<tr class="header">
<th>情况</th>
<th>构成方法</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>一般情况</td>
<td>加-s</td>
<td>bag-bags</td>
</tr>
<tr class="even">
<td>以s, sh, ch, x等结尾</td>
<td>加-es</td>
<td>peach-peaches</td>
</tr>
<tr class="odd">
<td>以辅音字母+y结尾</td>
<td>变y为i再加es</td>
<td>baby-babies</td>
</tr>
</tbody>
</table>
<h3 id="名词的格">名词的格</h3>
<p>有些名词可以加“‘s”来表示所有关系，带这种词尾的名词形式称为该<strong>名词的所有格</strong>，如：a
teacher's book。</p>
<p>名词所有格的规则如下：</p>
<ul>
<li>单数名词词尾加“'s”，复数名词词尾没有s，也要加“'s”。eg. the boy's bag
男孩的书包，men's room 男厕所。</li>
<li>若名词已有复数词尾-s ，只加“'”。eg. the workers’
struggle工人的斗争</li>
</ul>
<h2 id="代词pronounpron.">2 代词(pronoun=&gt;pron.)</h2>
<h3 id="定义-1">定义</h3>
<p>用来<strong>代指</strong>名词。</p>
<h3 id="分类-1">分类</h3>
<ul>
<li>人称代词（I, me, we, us etc.）</li>
<li>物主代词（my, our; mine, ours etc.）</li>
<li>反身代词（myself, ourselves etc.）</li>
<li>相互代词（each other, another）</li>
<li>疑问代词（who,what, how, why etc.）</li>
<li>不定代词（some, any, both, many etc.）</li>
<li>指示代词（this/that, these/those）</li>
</ul>
<p>（能做到识别出一个词是代词即可，不用刻意记忆代词的分类）</p>
<h3 id="并列人称代词">并列人称代词</h3>
<p>不同人称代词并列时，需要遵循一定的排序规则</p>
<ul>
<li>单数人称代词：二、三、一 eg. you, he and I</li>
<li>复数人称代词：一、二、三 eg. we, you and they</li>
</ul>
<h2 id="形容词adjectiveadj.">3 形容词(adjective=&gt;adj.)</h2>
<h3 id="定义-2">定义</h3>
<p>描写和修饰<strong>名词或代词，表示人或物的性质、状态、特征或属性。</strong>eg.
beautiful, ugly, big, small</p>
<p>通常做<strong>定语，或者表语、补语、状语</strong>。</p>
<p><strong>形容词作定语修饰名词时，要放在名词之前。如果形容词修饰以-thing为字尾的词语时，要放在这些词之后。eg.
something nice</strong></p>
<h3 id="形容词表示类别和整体">形容词表示类别和整体</h3>
<p>某些形容词加上定冠词可以泛指一类人，与谓语动词的复数连接。eg. the
dead，the living，the rich，the poor，the blind，the hungry</p>
<h2 id="动词verbv.">4 动词(verb=&gt;v.)</h2>
<h3 id="定义-3">定义</h3>
<p>表示动作或者状态。</p>
<h3 id="分类-2">分类</h3>
<ul>
<li>系动词（be, seem, look, sound etc.）</li>
<li>助动词（do, does, did etc.）</li>
<li>情态动词（can, will, shall, must etc.）、</li>
<li>实义动词（分为及物动词和非及物动词）
<ul>
<li>及物动词（vt.）后面可直接跟宾语 eg. love (you)</li>
<li>非及物动词（vi.）后不可以直接跟宾语。eg. go</li>
</ul></li>
</ul>
<h3 id="系动词分类">系动词分类</h3>
<ul>
<li>状态系动词：表示主语状态，只有be</li>
<li>持续系动词：表示主语保持一种状态或态度， eg. keep, stat, lie</li>
<li>表像系动词：表示“看起来像”，eg. seem, appear, look</li>
<li>感官系动词：表示感官，eg. feel, smell, sound, taste</li>
<li>变化系动词：表示主语变成什么样子，eg. become, grow, go</li>
<li>终止系动词：表示主语已终止动作，eg. prove, turn out</li>
</ul>
<h2 id="副词adverbadv.">5 副词(adverb=&gt;adv.)</h2>
<h3 id="定义-4">定义</h3>
<p>句子中<strong>表示行为或状态特征的词</strong>，用以修饰动词、形容词、其他副词或全句，表示时间、地点、程度、方式等概念。</p>
<h3 id="分类-3">分类</h3>
<p>时间副词、频率副词、地点副词、方式副词、程度副词、疑问副词、连接副词、关系副词等。</p>
<h2 id="数词numeralnum.">6 数词(numeral=&gt;num.)</h2>
<p><strong>定义：</strong>表示数字的词。</p>
<p><strong>分类：</strong></p>
<ul>
<li>基数词（one, two, three）</li>
<li>序数词（first, second, third）</li>
</ul>
<h2 id="冠词articleart.">7 冠词(article=&gt;art.)</h2>
<h3 id="定义-5">定义</h3>
<p>放在名词前面，表示名词所指的人、物。</p>
<h3 id="分类-4">分类</h3>
<ul>
<li>定冠词：the</li>
<li>不定冠词：a/ an</li>
</ul>
<h3 id="定冠词用法">定冠词用法</h3>
<table>
<colgroup>
<col style="width: 44%" />
<col style="width: 55%" />
</colgroup>
<thead>
<tr class="header">
<th>用法</th>
<th>例句</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>特指双方都明白的人或物</td>
<td>Take the medicine.</td>
</tr>
<tr class="even">
<td>上文提到过的人或事</td>
<td>He bought a house. I’ve been to the house.</td>
</tr>
<tr class="odd">
<td>指世上独一物二的事物</td>
<td>the sun, the sky, the moon, the earth</td>
</tr>
<tr class="even">
<td>单数名词连用表示一类事物</td>
<td>the dollar; the fox</td>
</tr>
<tr class="odd">
<td>用在序数词和形容词最高级之前</td>
<td>I live on the second floor.</td>
</tr>
<tr class="even">
<td>与复数名词连用，指整个群体</td>
<td>They are the teachers of this school.</td>
</tr>
<tr class="odd">
<td>用在专有名词前</td>
<td>the People's Republic of China</td>
</tr>
<tr class="even">
<td>用在姓氏的复数名词之前，表示一家人</td>
<td>the Greens</td>
</tr>
</tbody>
</table>
<h2 id="介词prepositionprep.">8 介词(preposition=&gt;prep.)</h2>
<h3 id="定义-6">定义</h3>
<p>用在<strong>名词、代词</strong>前，表示名词、代词等与其它词的关系。</p>
<h3 id="分类-5">分类</h3>
<ul>
<li>地点（位置、范围）介词：eg. from来自..., in在...里面, at在…处</li>
<li>方向（目标趋向）介词：eg. around绕着..., through穿过...</li>
<li>时间介词：eg. at在… (时刻), on在(某日), in在(上/下午)</li>
<li>方式介词：eg. by用/由/乘坐/被...,
on骑(车)/徒(步),通过(收音机/电视机)</li>
<li>涉及介词：eg. about关于...</li>
</ul>
<p>介词与其他词一起构成介词短语，eg. in the book, with you, on the
bridge</p>
<h2 id="连词conjunctionconj.">9 连词(conjunction=&gt;conj.)</h2>
<h3 id="定义-7">定义</h3>
<p>连词是<strong>连接词与词，短语与短语，句子与句子</strong>的词语。</p>
<h3 id="分类-6">分类</h3>
<ul>
<li>并列连词（and, or, etc.）</li>
<li>转折连词（but）</li>
<li>因果连词（therefore, because, etc.）</li>
</ul>
<h2 id="感叹词interjectioninterj.">10
感叹词(interjection=&gt;interj.)</h2>
<h3 id="定义-8">定义</h3>
<p>表示说话时情感的词。eg. ah, oh, wow, ha, hey</p>
]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>模型自动超参数优化算法</title>
    <url>/2023/11/19/HPO-method/</url>
    <content><![CDATA[<h2
id="单保真优化算法single-fidelity-optimization-algorithms">单保真优化算法(Single-Fidelity
Optimization Algorithms)</h2>
<p>单保真优化算法即为传统的优化算法，仅考虑在一个特定的评估条件下对模型性能的优化。通常，这个条件是某个单一的性能指标，例如在完整数据集上的准确率。</p>
<span id="more"></span>
<h3 id="网格搜索grid-search-gs">1 网格搜索(Grid Search, GS)</h3>
<h4 id="定义">1.1 定义</h4>
<p>网格搜索是一种穷举搜索方法，其通过遍历搜索空间中所有可能的组合来寻找最优超参数。</p>
<p>网格搜索首先为每个超参数设定一组候选值，然后生成这些候选值的笛卡尔积，形成搜索空间，接下来会对每个超参数组合进行模型训练和评估，从而找到性能最佳的超参数组合。</p>
<h4 id="优缺点">1.2 优缺点</h4>
<p><strong>优点：</strong>网格搜索确保可以找到全局最优的超参数组合。</p>
<p><strong>缺点：</strong>当超参数的数量和候选值较多时，会导致生成的搜索空间较大，应用网格搜索将十分消耗计算资源。</p>
<p>可以选择固定多数超参数，分别对1-2个超参数调优的方式在一定程度上降低网格搜索的计算量。但该方法难以自动化执行，且由于目标函数一般为非凸，容易陷入局部最小值。</p>
<h3 id="随机搜索random-search-rs">2 随机搜索(Random Search, RS)</h3>
<h4 id="定义-1">2.1 定义</h4>
<p>随机搜索是一种随机化的搜索方法，通过随机采样超参数组合来寻找最优超参数。</p>
<h4 id="优缺点-1">2.2 优缺点</h4>
<p><strong>优点：</strong>相较于网格搜索，随机搜索的计算成本较低，有可能在较短时间内找到较好的超参数组合。</p>
<p><strong>缺点：</strong>随机搜索不保证可以找到全局最优解，且对于超参数空间的分布不均匀的情况可能效果较差。</p>
<h3 id="贝叶斯优化bayesian-optimization-bo">3 贝叶斯优化(Bayesian
Optimization, BO)</h3>
<h4 id="定义-2">3.1 定义</h4>
<p>贝叶斯优化是一种基于概率模型的全局优化方法，通过构建目标函数的概率模型（一般为高斯过程），预测未观测点的目标函数值和不确定性，在每次迭代中个根据采集函数确定下一个采样点进行评估，以最小化目标函数，寻找最优超参数。</p>
<h4 id="优缺点-2">3.2 优缺点</h4>
<p><strong>优点：</strong>BO算法考虑之前的参数信息，在低维空间中，能够在相对较少的迭代次数中找到全局最优解，性能显著优于网格搜索和随机搜索。</p>
<p><strong>缺点：</strong>当参数较多时，容易发生维度爆炸，且会需要消耗大量的资源及时间。且那些具有未知平滑度和有噪声的高维、非凸函数，BO算法往往很难对其进行拟合和优化，而且通常BO算法都有很强的假设条件，而这些条件一般又很难满足。</p>
<h2
id="多保真优化算法multi-fidelity-optimization-algorithms">多保真优化算法(Multi-Fidelity
Optimization Algorithms)</h2>
<p>多保真度优化考虑了在多个评估条件下对模型性能的优化，可以是在不同的训练时间、资源预算、数据规模等条件下评估模型性能。这对于资源有限的任务，如在大数据集上的AutoML中，可以更有效地进行模型选择和优化。</p>
<h3 id="successive-halving算法sh">4 Successive Halving算法(SH)</h3>
<h4 id="定义-3">4.1 定义</h4>
<p>Successive Halving
算法是一种高效并行化的优化算法，其基本思想为，在每一轮中对超参数组合均匀的分配预算并进行验证评估，根据验证结果淘汰一半表现差的超参数组合，之后重复迭代上述过程直到找到最优的超参数组合。</p>
<p>其中，算法中提到的预算，根据不同的应用场景可以有不同的定义，例如：</p>
<ul>
<li>迭代算法的迭代数(如：神经网络的epoch、随机森林，GBDT的树的个数)</li>
<li>机器学习算法所使用的样本数</li>
<li>深度强化学习中的尝试数 等</li>
</ul>
<h4 id="优缺点-3">4.2 优缺点</h4>
<p><strong>优点：</strong>SH算法在每一轮中并行评估多个超参数组合，提高了搜索的效率。通过在每一轮中动态调整资源分配，为性能较好的超参数组合分配更多资源，实现了资源消耗和搜索性能的权衡。</p>
<p><strong>缺点：</strong>SH算法对初始条件敏感，因为该算法需要将超参数组合数量和总资源量作为算法输入，因此需要在算法开始前进行超参数组合和资源之间的权衡。而实际上，在评估之前，无法得知设置超参数组合的数量和资源量的最优值。</p>
<h3 id="hyperband算法hb">5 Hyperband算法(HB)</h3>
<h4 id="定义-4">5.1 定义</h4>
<p>Hyperband 的基本思想是通过在不同的超参数配置上运行不同的 Bandit
算法实例，实现对多组配置的并行评估，并使用 Successive Halving
的策略进行资源动态分配。</p>
<p>在 Hyperband 中，每个 Successive Halving 阶段都有一个 Bandit
算法的实例运行。该实例的任务是在给定的资源限制下，对一组超参数配置进行评估，并选择性能最好的一部分配置进入下一轮。</p>
<h4 id="步骤">5.2 步骤</h4>
<img src="/2023/11/19/HPO-method/img-1.png" class="" title="img">
<p>算法输入：</p>
<ul>
<li><span
class="math inline">\(R\)</span>：单个超参数组合所能分配的最大预算</li>
<li><span
class="math inline">\(\eta\)</span>：用于控制每次迭代后淘汰参数设置的比例的参数</li>
</ul>
<p>其他参数含义：</p>
<ul>
<li><span
class="math inline">\(s_{max}\)</span>：控制总预算大小的参数</li>
<li><span class="math inline">\(B\)</span>：总预算</li>
<li><span class="math inline">\(n\)</span>：采样的超参数配置数</li>
<li><span
class="math inline">\(r\)</span>：单个超参数组合实际分配到的预算</li>
</ul>
<p>函数含义：</p>
<ul>
<li><code>get_hyperparameter_configuration(n)</code>：采样得到n组不同的超参数设置</li>
<li><code>run_then_return_val_loss(t,r_i)</code>：根据指定的参数设置和预算计算valid
loss</li>
<li><code>top_k()</code>：根据指定参数选择前k个组合</li>
</ul>
<h4 id="优缺点-4">5.4 优缺点</h4>
<p><strong>优点：</strong>HB算法在Successive
Halving算法的基础上引入了更多的并行性，能够在不同的尺度上进行搜索，通过调整参数，可以在不同的计算资源预算下运行HB，具备更高的并行性和更加灵活的资源利用方式。</p>
<p><strong>缺点：</strong>HB算法同样对初始配置敏感，不同的初始配置可能导致不同的搜索路径和结果。</p>
<h3 id="bayesian-optimization-and-hyperband算法bohb">6 Bayesian
Optimization and Hyperband算法(BOHB)</h3>
<h4 id="定义-5">6.1 定义</h4>
<p>在HB算法中，采样超参数配置使用的方法是均匀随机采样，而BOHB算法在HB算法的基础上，结合贝叶斯优化算法，更加合理的采样超参数配置。</p>
<h4 id="优缺点-5">6.2 优缺点</h4>
<p><strong>优点：</strong>
BOHB算法结合了HB算法和贝叶斯优化，通过建模和利用先前评估的配置来更智能地选择下一个要评估的配置，进一步提高了搜索效率。</p>
<p><strong>缺点：</strong>引入贝叶斯优化后，提升了整个算法的复杂程度，会引入一定的计算开销。因此更加适用于大型搜索空间，对于较小的问题或计算资源非常有限的情况，BOHB算法并不适用。</p>
]]></content>
      <categories>
        <category>Learning Notes</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
        <tag>HPO</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/11/15/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
